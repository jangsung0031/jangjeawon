"""
LLM ì„œë¹„ìŠ¤ - GPT-4o minië¥¼ í™œìš©í•œ ë°©ì œë²• ì œì‹œ
"""
import os
from openai import OpenAI
from typing import Optional
import logging

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

logger = logging.getLogger(__name__)


class PlantDiseaseAdvisor:
    """ì‹ë¬¼ ë³‘ì¶©í•´ ë°©ì œë²• ì œì‹œ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì‚¬ìš© ê°€ëŠ¥)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        
        if not self.api_key:
            logger.warning("âš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            logger.warning(f"   í˜„ì¬ í™˜ê²½ ë³€ìˆ˜ í™•ì¸: OPENAI_API_KEY={'ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'ì—†ìŒ'}")
            self.client = None
        else:
            try:
                # httpx í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ proxies ë¬¸ì œ í•´ê²°
                import httpx
                
                # í™˜ê²½ ë³€ìˆ˜ì—ì„œ proxies ì™„ì „íˆ ì œê±°
                proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
                saved_proxies = {}
                for var in proxy_env_vars:
                    if var in os.environ:
                        saved_proxies[var] = os.environ.pop(var)
                
                try:
                    # httpx í´ë¼ì´ì–¸íŠ¸ë¥¼ proxies ê´€ë ¨ ì„¤ì • ì—†ì´ ìƒì„±
                    http_client = httpx.Client(timeout=60.0)
                    
                    self.client = OpenAI(
                        api_key=self.api_key,
                        http_client=http_client
                    )
                    logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                    logger.info(f"   API í‚¤ ê¸¸ì´: {len(self.api_key)} ë¬¸ì")
                finally:
                    # í™˜ê²½ ë³€ìˆ˜ ë³µì›
                    for var, value in saved_proxies.items():
                        os.environ[var] = value
                        
            except Exception as e:
                logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
                self.client = None
    
    def get_treatment_advice(
        self, 
        plant_species: str, 
        disease: str,
        confidence: float,
        user_notes: Optional[str] = None
    ) -> str:
        """
        ì‹ë¬¼ ë³‘ì¶©í•´ì— ëŒ€í•œ ë°©ì œë²• ë° ì˜ˆë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        Args:
            plant_species: ì‹ë¬¼ ì¢… (ì˜ˆ: "Tomato")
            disease: ë³‘ì¶©í•´ëª… (ì˜ˆ: "Early blight")
            confidence: ì‹ ë¢°ë„ (0.0 ~ 1.0)
            user_notes: ì‚¬ìš©ì ì¶”ê°€ ì˜ê²¬ (ì„ íƒì‚¬í•­)
            
        Returns:
            ë°©ì œë²• ë° ì˜ˆë°©ë²• í…ìŠ¤íŠ¸
        """
        if not self.client:
            return "âš ï¸  AI ë°©ì œë²• ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(plant_species, disease, confidence, user_notes)
            
            # GPT-4o mini í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ì‹ë¬¼ ë³‘ì¶©í•´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                            "ë†ë¶€ì™€ ê°€ì • ì›ì˜ˆê°€ë“¤ì—ê²Œ ì‹¤ìš©ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ "
                            "ë°©ì œë²•ê³¼ ì˜ˆë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. "
                            "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ì‘ì„±í•˜ë©°, "
                            "êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‹¨ê³„ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=800
            )
            
            advice = response.choices[0].message.content.strip()
            logger.info(f"âœ… LLM ë°©ì œë²• ìƒì„± ì™„ë£Œ (ì‹ë¬¼: {plant_species}, ë³‘ì¶©í•´: {disease})")
            
            return advice
            
        except Exception as e:
            logger.error(f"âŒ LLM í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return f"âš ï¸  ë°©ì œë²• ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def get_user_notes_advice(self, user_notes: str) -> str:
        """
        ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œ ì‚¬ìš©ìì˜ ì¶”ê°€ ì„¤ëª…ë§Œìœ¼ë¡œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        Args:
            user_notes: ì‚¬ìš©ì ì¶”ê°€ ì˜ê²¬
            
        Returns:
            ì¡°ì–¸ í…ìŠ¤íŠ¸
        """
        if not self.client:
            return "âš ï¸  AI ë°©ì œë²• ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        if not user_notes or not user_notes.strip():
            return None
        
        try:
            prompt = f"""
ì‚¬ìš©ìê°€ ì‹ë¬¼ ë³‘ì¶©í•´ ì¦ìƒì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤:

"{user_notes}"

ìœ„ ì„¤ëª…ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. ì¦ìƒ ë¶„ì„ (3-4ë¬¸ì¥)
   - ì‚¬ìš©ìê°€ ì„¤ëª…í•œ ì¦ìƒì— ëŒ€í•œ ì¼ë°˜ì ì¸ ë¶„ì„
   - ê°€ëŠ¥í•œ ì›ì¸ë“¤

2. ì¦‰ì‹œ ì¡°ì¹˜ ë°©ë²•
   - ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” ì‘ê¸‰ ì¡°ì¹˜
   - ì¶”ê°€ í”¼í•´ ë°©ì§€ ë°©ë²•

3. ì¼ë°˜ì ì¸ ê´€ë¦¬ ì¡°ì–¸
   - ë¬¼ ì£¼ê¸°, í†µí’, ì¡°ëª… ë“± í™˜ê²½ ê´€ë¦¬
   - ì˜ˆë°©ì„ ìœ„í•œ íŒ

4. ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥
   - ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ ë³‘ì›ê·  ê²€ì‚¬ ë“±ì„ ê¶Œì¥

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ê° ì„¹ì…˜ì€ ì´ëª¨ì§€(ğŸ”, ğŸš¨, ğŸŒ±, ğŸ’¡)ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ì‹ë¬¼ ë³‘ì¶©í•´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                            "ì‚¬ìš©ìì˜ ì„¤ëª…ë§Œìœ¼ë¡œ ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œ ì¡°ì–¸ì„ ì œê³µí•˜ë˜, "
                            "ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ë” ë§ì€ ì •ë³´ë‚˜ ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•¨ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
                        )
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=600
            )
            
            advice = response.choices[0].message.content.strip()
            logger.info(f"âœ… ì‚¬ìš©ì ì„¤ëª… ê¸°ë°˜ ì¡°ì–¸ ìƒì„± ì™„ë£Œ")
            
            return advice
            
        except Exception as e:
            logger.error(f"âŒ LLM í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def translate_to_korean(self, english_text: str, context: str = "plant") -> str:
        """
        ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
        
        Args:
            english_text: ì˜ì–´ í…ìŠ¤íŠ¸
            context: ë²ˆì—­ ì»¨í…ìŠ¤íŠ¸ ("plant" ë˜ëŠ” "disease")
            
        Returns:
            í•œêµ­ì–´ ë²ˆì—­ í…ìŠ¤íŠ¸
        """
        if not self.client:
            return english_text  # API í‚¤ê°€ ì—†ìœ¼ë©´ ì›ë¬¸ ë°˜í™˜
        
        if not english_text or not english_text.strip():
            return english_text
        
        try:
            if context == "plant":
                system_prompt = "ë‹¹ì‹ ì€ ì‹ë¬¼í•™ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì‹ë¬¼ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•  ë•ŒëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í•œêµ­ì–´ ëª…ì¹­ì„ ì‚¬ìš©í•˜ì„¸ìš”."
                user_prompt = f"ë‹¤ìŒ ì‹ë¬¼ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ì´ë¦„ë§Œ ë‹µë³€í•˜ì„¸ìš”: {english_text}"
            else:  # disease
                system_prompt = "ë‹¹ì‹ ì€ ì‹ë¬¼ ë³‘ë¦¬í•™ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ë³‘ì¶©í•´ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•  ë•ŒëŠ” ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                user_prompt = f"ë‹¤ìŒ ì‹ë¬¼ ë³‘ì¶©í•´ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ì´ë¦„ë§Œ ë‹µë³€í•˜ì„¸ìš”: {english_text}"
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=50
            )
            
            translated = response.choices[0].message.content.strip()
            logger.info(f"âœ… ë²ˆì—­ ì™„ë£Œ: {english_text} -> {translated}")
            
            return translated
            
        except Exception as e:
            logger.error(f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {str(e)}")
            return english_text  # ì˜¤ë¥˜ ì‹œ ì›ë¬¸ ë°˜í™˜
    
    def _build_prompt(
        self, 
        plant_species: str, 
        disease: str,
        confidence: float,
        user_notes: Optional[str]
    ) -> str:
        """ë°©ì œë²• ìš”ì²­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        
        prompt = f"""
ì‹ë¬¼ ë³‘ì¶©í•´ ì§„ë‹¨ ê²°ê³¼:
- ì‹ë¬¼ ì¢…: {plant_species}
- ë³‘ì¶©í•´/ìƒíƒœ: {disease}
- AI ì‹ ë¢°ë„: {confidence * 100:.1f}%
"""
        
        if user_notes and user_notes.strip():
            prompt += f"\nì‚¬ìš©ì ì¶”ê°€ ì •ë³´:\n{user_notes}\n"
        
        prompt += """
ìœ„ ì§„ë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. ë³‘ì¶©í•´ ê°œìš” (2-3ë¬¸ì¥)
   - ì´ ë³‘ì¶©í•´ê°€ ë¬´ì—‡ì¸ì§€ ê°„ë‹¨íˆ ì„¤ëª…
   - ì£¼ìš” ì¦ìƒ ë° íŠ¹ì§•

2. ì¦‰ì‹œ ì¡°ì¹˜ ë°©ë²• (ê¸´ê¸‰ ëŒ€ì‘)
   - ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” ì‘ê¸‰ ì¡°ì¹˜
   - ë³‘ í™•ì‚° ë°©ì§€ ë°©ë²•

3. ë°©ì œë²• (ë‹¨ê³„ë³„)
   - í™”í•™ì  ë°©ì œ (í•„ìš”ì‹œ ë†ì•½ëª… í¬í•¨)
   - ì¹œí™˜ê²½ ë°©ì œ (ìœ ê¸°ë† ë°©ë²•)
   - ë¬¼ë¦¬ì  ë°©ì œ (ì œê±°, ê²©ë¦¬ ë“±)

4. ì˜ˆë°©ë²•
   - ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ì¥ê¸° ê´€ë¦¬ ë°©ë²•
   - í™˜ê²½ ê´€ë¦¬ (í†µí’, ìŠµë„, ë¬¼ ì£¼ê¸° ë“±)

5. ì£¼ì˜ì‚¬í•­
   - ë°©ì œ ì‹œ ì£¼ì˜í•  ì 
   - í”¼í•´ì•¼ í•  í–‰ë™

ë‹µë³€ì€ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ê° ì„¹ì…˜ì€ ì´ëª¨ì§€(ğŸ“Œ, ğŸš¨, ğŸ’Š, ğŸ›¡ï¸, âš ï¸)ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
"""
        
        return prompt


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_advisor_instance: Optional[PlantDiseaseAdvisor] = None


def get_advisor() -> PlantDiseaseAdvisor:
    """
    PlantDiseaseAdvisor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global _advisor_instance
    if _advisor_instance is None:
        _advisor_instance = PlantDiseaseAdvisor()
    return _advisor_instance

